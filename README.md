# VideoGameClassification-ML

## üéÆ Clasificaci√≥n de Videojuegos mediante Machine Learning

Este proyecto tiene como objetivo desarrollar un modelo capaz de identificar distintos videojuegos a partir de im√°genes, utilizando t√©cnicas de Aprendizaje Autom√°tico (Machine Learning). Esta clasificaci√≥n puede ser √∫til para sistemas de recomendaci√≥n, organizaci√≥n de bibliotecas de juegos o an√°lisis de contenido multimedia relacionado con videojuegos.

Se emplea **Aprendizaje Supervisado**, una rama del Machine Learning en la que el modelo aprende a reconocer patrones a partir de un conjunto de datos etiquetado. A trav√©s del entrenamiento con estas im√°genes, el modelo es capaz de predecir correctamente la categor√≠a o el videojuego correspondiente de nuevas im√°genes no vistas.

---

## üïπÔ∏è Clases del Modelo

El modelo ha sido entrenado para reconocer y clasificar im√°genes de distintos videojuegos populares, cada uno con caracter√≠sticas visuales y est√©ticas particulares. Estas son las categor√≠as de videojuegos que el modelo identifica, junto con una breve descripci√≥n de cada una:

- **Dead by Daylight**  
  Juego multijugador asim√©trico (1 vs 4) de horror y supervivencia. Un jugador asume el rol de asesino, mientras los dem√°s intentan sobrevivir.  
  **Estilo visual:** Entornos oscuros, iluminaci√≥n tenue y predominancia de colores opacos y sombr√≠os.  
  **Perspectiva:** 3D en tercera persona.

- **Counter-Strike: Global Offensive (CS:GO)**  
  Shooter t√°ctico multijugador por equipos (5v5), centrado en enfrentamientos entre terroristas y antiterroristas.  
  **Estilo visual:** Ambientes urbanos o industriales, paleta de colores realista y sobria.  
  **Perspectiva:** 3D en primera persona.

- **Valorant**  
  Shooter t√°ctico multijugador que combina mec√°nicas de disparo con habilidades √∫nicas por personaje.  
  **Estilo visual:** Gr√°ficos estilizados con colores vivos, mapas bien iluminados y efectos visuales llamativos.  
  **Perspectiva:** 3D en primera persona.

- **Clash Royale**  
  Juego de estrategia en tiempo real para m√≥viles, basado en cartas coleccionables y batallas r√°pidas entre dos jugadores.  
  **Estilo visual:** Est√©tica caricaturesca en 2.5D, colores brillantes y animaciones simplificadas.  
  **Perspectiva:** Vista cenital (de arriba hacia abajo).

- **Minecraft**  
  Juego de construcci√≥n y supervivencia en un mundo abierto generado por bloques.  
  **Estilo visual:** Est√©tica pixelada en 3D, colores variados pero con texturas simples y cuadradas.  
  **Perspectiva:** Puede alternar entre primera y tercera persona.

- **Overwatch**  
  Shooter por equipos con enfoque en h√©roes, cada uno con habilidades y roles espec√≠ficos.  
  **Estilo visual:** Gr√°ficos coloridos y estilizados, ambientaciones futuristas y personajes visualmente distintivos.  
  **Perspectiva:** 3D en primera persona.

---

## üìÅ Generaci√≥n y selecci√≥n del conjunto de datos

Para este proyecto se utiliz√≥ el dataset [**Videogame Image Classification**](https://www.kaggle.com/datasets/juanmartinzabala/videogame-image-classification?resource=download-directory) disponible en Kaggle, el cual contiene capturas de pantalla de diversos videojuegos populares.

### üîç Proceso de limpieza y selecci√≥n

A partir del conjunto original, se realiz√≥ una limpieza significativa, seleccionando √∫nicamente 6 de las 21 clases disponibles. Esta decisi√≥n se tom√≥ porque muchas clases presentaban im√°genes con problemas como:

- Capturas limitadas a una sola zona del videojuego.
- Presencia de elementos no relacionados (como c√°maras de streamers o superposiciones gr√°ficas de transmisiones).
- Poca diversidad en escenarios y contenido visual del juego.

Estas limitaciones pod√≠an afectar negativamente la capacidad del modelo para generalizar, por lo que se opt√≥ por trabajar solo con clases visualmente m√°s consistentes y representativas.

### üì¶ Reducci√≥n y balanceo del dataset

Cada clase del dataset original conten√≠a aproximadamente 4,000 im√°genes para entrenamiento y 1,000 para prueba. No obstante, se redujo intencionalmente la cantidad de im√°genes a un aproximado de:

- **700 im√°genes por clase para entrenamiento**
- **150 im√°genes por clase para prueba**
  
Adicionalmente se uso el 10% de datos de cada clase como datos de validaci√≥n.

Esta reducci√≥n tuvo como objetivo priorizar la calidad y la diversidad del contenido, manteniendo un balance entre clases y una proporci√≥n de **70% para entrenamiento, 10% para validaci√≥n y 20% para prueba**.

---

## üìä Distribuci√≥n de los datos

Despu√©s del proceso de limpieza y selecci√≥n, el conjunto de datos qued√≥ conformado por un total de **4,451 im√°genes para entrenamiento**, distribuidas de manera balanceada entre las seis clases seleccionadas:

| Videojuego           | Im√°genes (train) |
|----------------------|------------------|
| Dead by Daylight     | 704              |
| Counter-Strike       | 733              |
| Valorant             | 789              |
| Clash Royale         | 718              |
| Minecraft            | 787              |
| Overwatch            | 720              |
| **Total**            | **4,451**        |

| Videojuego           | Im√°genes (test) |
|----------------------|------------------|
| Dead by Daylight     | 157              |
| Counter-Strike       | 154              |
| Valorant             | 165              |
| Clash Royale         | 161              |
| Minecraft            | 157              |
| Overwatch            | 151              |
| **Total**            | **945**        |

Esta distribuci√≥n permite mantener una representaci√≥n relativamente equilibrada entre las clases, lo que ayuda a que el modelo aprenda patrones visuales distintivos de cada videojuego. En caso de ser necesario, se podr√° incrementar el n√∫mero de im√°genes por clase para mejorar el rendimiento del modelo o reforzar aquellas categor√≠as que presenten menor precisi√≥n durante las pruebas.

## üõ†Ô∏è Preprocesado y t√©cnicas de aumento de datos

Para mejorar la capacidad del modelo para generalizar y hacerlo m√°s robusto frente a las distintas condiciones gr√°ficas en las que pueden presentarse los videojuegos (por ejemplo, baja calidad, capturas con diferente iluminaci√≥n o resoluci√≥n), se aplicaron las siguientes t√©cnicas de preprocesamiento:

### üîπ Reescalado (normalizaci√≥n)
Cada valor de p√≠xel se divide entre **255** (`rescale=1./255`) para transformar el rango de los p√≠xeles de **[0, 255] a [0, 1]**. Esto estabiliza el proceso de optimizaci√≥n y mejora la convergencia del modelo durante el entrenamiento.

### üîπ Redimensionamiento (resize)
Todas las im√°genes se redimensionaron al tama√±o de **224x224 p√≠xeles**, que es un est√°ndar com√∫n para modelos de redes neuronales convolucionales (CNN). Esto asegura consistencia en la entrada de datos.

### üîπ Aumento de datos (data augmentation)
Se aplicaron transformaciones aleatorias a las im√°genes del conjunto de entrenamiento para simular una mayor diversidad visual sin necesidad de agregar nuevas im√°genes. Las transformaciones incluyen:

- **Giro horizontal aleatorio** (`RandomFlip`)
- **Rotaci√≥n aleatoria** (`RandomRotation`)
- **Zoom aleatorio** (`RandomZoom`)

Estas t√©cnicas ayudan a reducir el sobreajuste y permiten que el modelo aprenda caracter√≠sticas m√°s generales del contenido visual.

![image](https://github.com/user-attachments/assets/65bc234d-d7e0-4083-ab72-3a0ad6e2556b)

## ü§ñ Construcci√≥n del modelo

### Arquitectura CNN
Una **Red Neuronal Convolucional (CNN)** es una arquitectura de red para Deep Learning que aprende directamente a partir de datos. Mediante capas de convoluci√≥n aprende filtros que, de forma jer√°rquica, reconocen desde bordes y texturas hasta composiciones visuales complejas; las capas de *max-pooling* comprimen la informaci√≥n, otorgando invarianza a traslaciones y escalas. As√≠, la CNN elimina la dependencia de descriptores manuales y se adapta a la gran variabilidad presente en las capturas de videojuegos.

![image](https://github.com/user-attachments/assets/eae4b4b3-83bc-462d-9d12-417ec1106cd6)

#### ¬øPor qu√© una CNN y no SVM / Random Forest?
- **Extracci√≥n de caracter√≠sticas autom√°tica.** La red aprende sola los filtros que distinguen *pixel-art* (Minecraft) de texturas realistas (CS:GO), algo que los enfoques basados en HOG + SVM no logran sin una ingenier√≠a manual costosa.  
- **Robustez a transformaciones.** Convoluci√≥n + pooling mantiene el rendimiento ante cambios de brillo, giros leves o escalados t√≠picos de un *screenshot*.  
- **Escalabilidad.** La arquitectura puede crecer (m√°s filtros/capas) o migrar, mientras que los modelos cl√°sicos requieren redefinir descriptores.  

> **Paper de Referencia**. Breve F. (2023) *From Pixels to Titles: Video Game Identification by Screenshots using Convolutional Neural Networks*, arXiv:2311.15963

### Composici√≥n de la CNN

| Bloque | Capa | Par√°metros clave | Prop√≥sito |
|--------|------|------------------|-----------|
| 1 | `Conv2D(32, 3√ó3)` + ReLU | Entrada `224√ó224√ó3` | Detecta bordes/texturas b√°sicas |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | Reduce resoluci√≥n, gana invarianza |
| 2 | `Conv2D(64, 3√ó3)` + ReLU | ‚Äî | Captura patrones intermedios |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | ‚Äî |
| 3 | `Conv2D(128, 3√ó3)` + ReLU | ‚Äî | Reconoce estructuras complejas (HUD, mapas) |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | ‚Äî |
| ‚Äî | `Flatten()` | ‚Äî | Pasa de 3-D a 1-D |
| ‚Äî | `Dense(128)` + ReLU | ‚Äî | Combina rasgos globales |
| ‚Äî | `Dense(6)` + Softmax | ‚Äî | Probabilidades para las 6 clases |

### Selecci√≥n de m√©tricas

| M√©trica | Qu√© mide | Por qu√© es √∫til |
|---------|----------|-----------------|
| **Accuracy** | Proporci√≥n de aciertos globales | Indicador general de desempe√±o |
| **Precisi√≥n** | TP / (TP + FP) por clase | Fiabilidad cuando el modelo ‚Äúafirma‚Äù ser un juego X |
| **Recall** | TP / (TP + FN) por clase | Cu√°ntas im√°genes reales de un juego X recupera |
| **F1-score (macro)** | Media balanceada de precisi√≥n y recall | Resume errores clase a clase |
| **Support** | N¬∫ de muestras por clase | Conteo de ejemplos reales que pertenecen a cada clase |

Adem√°s se genera una **matriz de confusi√≥n** para visualizar r√°pidamente en qu√© t√≠tulos la red se equivoca 
![image](https://github.com/user-attachments/assets/f5dcda05-71de-4d6a-a1dc-14b5de5f12ed)


### Compilaci√≥n y entrenamiento

| Elemento | Configuraci√≥n | Razonamiento |
|----------|--------------|--------------|
| **Optimizador** | Adam | Convergencia estable y sin ajuste manual del *learning rate* |
| **P√©rdida** | `categorical_crossentropy` | Adecuada para clasificaci√≥n *one-hot* |
| **M√©trica primaria** | `accuracy` | Feedback r√°pido en cada epoch |

### üîß Configuraci√≥n de entrenamiento

| Hiperpar√°metro | Valor usado | Por qu√© se eligi√≥ |
|----------------|------------|-------------------|
| **Batch size** | **32** | Con 32 im√°genes por lote se logra suficiente aleatoriedad para que el gradiente sea representativo y al mismo tiempo, el consumo de VRAM sea moderado |
| **√âpocas** | **10** | Se realiz√≥ una primera corrida de 10 pasadas completas sobre los datos. Las curvas *loss/accuracy* mostraron estabilizaci√≥n y ning√∫n signo de overfitting prematuro. |
| **Steps per epoch** | **126** | Se revisan 126 imagenes por √©poca ( 4 006 im√°genes de entrenamiento / batch size). Esto permite que cada imagen sea procesada exactamente una vez por √©poca. |
| **Validation steps** | **14** | El conjunto de validaci√≥n qued√≥ en 445 im√°genes ‚Üí `ceil(445 / 32) = 14` lotes. Suficiente para estimar la generalizaci√≥n sin alargar demasiado cada √©poca. |
| **Pesos de clase** | **No aplicados** | El dataset result√≥ equilibrado (‚âà 700 ¬± 70 im√°genes por clase). Por ello no fue necesario ponderar la p√©rdida; todas las clases contribuyen por igual durante el aprendizaje. |


