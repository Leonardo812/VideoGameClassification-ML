# VideoGameClassification-ML

## ðŸŽ® ClasificaciÃ³n de Videojuegos mediante Machine Learning

Este proyecto tiene como objetivo desarrollar un modelo capaz de identificar distintos videojuegos a partir de imÃ¡genes, utilizando tÃ©cnicas de Aprendizaje AutomÃ¡tico (Machine Learning). Esta clasificaciÃ³n puede ser Ãºtil para sistemas de recomendaciÃ³n, organizaciÃ³n de bibliotecas de juegos o anÃ¡lisis de contenido multimedia relacionado con videojuegos.

Se emplea **Aprendizaje Supervisado**, una rama del Machine Learning en la que el modelo aprende a reconocer patrones a partir de un conjunto de datos etiquetado. A travÃ©s del entrenamiento con estas imÃ¡genes, el modelo es capaz de predecir correctamente la categorÃ­a o el videojuego correspondiente de nuevas imÃ¡genes no vistas.

---

## ðŸ•¹ï¸ Clases del Modelo

El modelo ha sido entrenado para reconocer y clasificar imÃ¡genes de distintos videojuegos populares, cada uno con caracterÃ­sticas visuales y estÃ©ticas particulares. Estas son las categorÃ­as de videojuegos que el modelo identifica, junto con una breve descripciÃ³n de cada una:

- **Dead by Daylight**  
  Juego multijugador asimÃ©trico (1 vs 4) de horror y supervivencia. Un jugador asume el rol de asesino, mientras los demÃ¡s intentan sobrevivir.  
  **Estilo visual:** Entornos oscuros, iluminaciÃ³n tenue y predominancia de colores opacos y sombrÃ­os.  
  **Perspectiva:** 3D en tercera persona.

- **Counter-Strike: Global Offensive (CS:GO)**  
  Shooter tÃ¡ctico multijugador por equipos (5v5), centrado en enfrentamientos entre terroristas y antiterroristas.  
  **Estilo visual:** Ambientes urbanos o industriales, paleta de colores realista y sobria.  
  **Perspectiva:** 3D en primera persona.

- **Valorant**  
  Shooter tÃ¡ctico multijugador que combina mecÃ¡nicas de disparo con habilidades Ãºnicas por personaje.  
  **Estilo visual:** GrÃ¡ficos estilizados con colores vivos, mapas bien iluminados y efectos visuales llamativos.  
  **Perspectiva:** 3D en primera persona.

- **Clash Royale**  
  Juego de estrategia en tiempo real para mÃ³viles, basado en cartas coleccionables y batallas rÃ¡pidas entre dos jugadores.  
  **Estilo visual:** EstÃ©tica caricaturesca en 2.5D, colores brillantes y animaciones simplificadas.  
  **Perspectiva:** Vista cenital (de arriba hacia abajo).

- **Minecraft**  
  Juego de construcciÃ³n y supervivencia en un mundo abierto generado por bloques.  
  **Estilo visual:** EstÃ©tica pixelada en 3D, colores variados pero con texturas simples y cuadradas.  
  **Perspectiva:** Puede alternar entre primera y tercera persona.

- **Overwatch**  
  Shooter por equipos con enfoque en hÃ©roes, cada uno con habilidades y roles especÃ­ficos.  
  **Estilo visual:** GrÃ¡ficos coloridos y estilizados, ambientaciones futuristas y personajes visualmente distintivos.  
  **Perspectiva:** 3D en primera persona.

---

## ðŸ“ GeneraciÃ³n y selecciÃ³n del conjunto de datos

Para este proyecto se utilizÃ³ el dataset [**Videogame Image Classification**](https://www.kaggle.com/datasets/juanmartinzabala/videogame-image-classification?resource=download-directory) disponible en Kaggle, el cual contiene capturas de pantalla de diversos videojuegos populares.

### ðŸ” Proceso de limpieza y selecciÃ³n

A partir del conjunto original, se realizÃ³ una limpieza significativa, seleccionando Ãºnicamente 6 de las 21 clases disponibles. Esta decisiÃ³n se tomÃ³ porque muchas clases presentaban imÃ¡genes con problemas como:

- Capturas limitadas a una sola zona del videojuego.
- Presencia de elementos no relacionados (como cÃ¡maras de streamers o superposiciones grÃ¡ficas de transmisiones).
- Poca diversidad en escenarios y contenido visual del juego.

Estas limitaciones podÃ­an afectar negativamente la capacidad del modelo para generalizar, por lo que se optÃ³ por trabajar solo con clases visualmente mÃ¡s consistentes y representativas.

### ðŸ“¦ ReducciÃ³n y balanceo del dataset

Cada clase del dataset original contenÃ­a aproximadamente 4,000 imÃ¡genes para entrenamiento y 1,000 para prueba. No obstante, se redujo intencionalmente la cantidad de imÃ¡genes a un aproximado de:

- **700 imÃ¡genes por clase para entrenamiento**
- **150 imÃ¡genes por clase para prueba**
  
Adicionalmente se uso el 10% de datos de cada clase como datos de validaciÃ³n.

Esta reducciÃ³n tuvo como objetivo priorizar la calidad y la diversidad del contenido, manteniendo un balance entre clases y una proporciÃ³n de **70% para entrenamiento, 10% para validaciÃ³n y 20% para prueba**.

---

## ðŸ“Š DistribuciÃ³n de los datos

DespuÃ©s del proceso de limpieza y selecciÃ³n, el conjunto de datos quedÃ³ conformado por un total de **4,451 imÃ¡genes para entrenamiento**, distribuidas de manera balanceada entre las seis clases seleccionadas:

| Videojuego           | ImÃ¡genes (train) |
|----------------------|------------------|
| Dead by Daylight     | 704              |
| Counter-Strike       | 733              |
| Valorant             | 789              |
| Clash Royale         | 718              |
| Minecraft            | 787              |
| Overwatch            | 720              |
| **Total**            | **4,451**        |

| Videojuego           | ImÃ¡genes (test) |
|----------------------|------------------|
| Dead by Daylight     | 157              |
| Counter-Strike       | 154              |
| Valorant             | 165              |
| Clash Royale         | 161              |
| Minecraft            | 157              |
| Overwatch            | 151              |
| **Total**            | **945**        |

Esta distribuciÃ³n permite mantener una representaciÃ³n relativamente equilibrada entre las clases, lo que ayuda a que el modelo aprenda patrones visuales distintivos de cada videojuego. En caso de ser necesario, se podrÃ¡ incrementar el nÃºmero de imÃ¡genes por clase para mejorar el rendimiento del modelo o reforzar aquellas categorÃ­as que presenten menor precisiÃ³n durante las pruebas.

## ðŸ› ï¸ Preprocesado y tÃ©cnicas de aumento de datos

Para mejorar la capacidad del modelo para generalizar y hacerlo mÃ¡s robusto frente a las distintas condiciones grÃ¡ficas en las que pueden presentarse los videojuegos (por ejemplo, baja calidad, capturas con diferente iluminaciÃ³n o resoluciÃ³n), se aplicaron las siguientes tÃ©cnicas de preprocesamiento:

### ðŸ”¹ Reescalado (normalizaciÃ³n)
Cada valor de pÃ­xel se divide entre **255** (`rescale=1./255`) para transformar el rango de los pÃ­xeles de **[0, 255] a [0, 1]**. Esto estabiliza el proceso de optimizaciÃ³n y mejora la convergencia del modelo durante el entrenamiento.

### ðŸ”¹ Redimensionamiento (resize)
Todas las imÃ¡genes se redimensionaron al tamaÃ±o de **224x224 pÃ­xeles**, que es un estÃ¡ndar comÃºn para modelos de redes neuronales convolucionales (CNN). Esto asegura consistencia en la entrada de datos.

### ðŸ”¹ Aumento de datos (data augmentation)
Se aplicaron transformaciones aleatorias a las imÃ¡genes del conjunto de entrenamiento para simular una mayor diversidad visual sin necesidad de agregar nuevas imÃ¡genes. Las transformaciones incluyen:

- **Giro horizontal aleatorio** (`RandomFlip`)
- **RotaciÃ³n aleatoria** (`RandomRotation`)
- **Zoom aleatorio** (`RandomZoom`)

Estas tÃ©cnicas ayudan a reducir el sobreajuste y permiten que el modelo aprenda caracterÃ­sticas mÃ¡s generales del contenido visual.

![image](https://github.com/user-attachments/assets/65bc234d-d7e0-4083-ab72-3a0ad6e2556b)

## ðŸ¤– ConstrucciÃ³n del modelo

### Arquitectura CNN
Una **Red Neuronal Convolucional (CNN)** es una arquitectura de red para Deep Learning que aprende directamente a partir de datos. Mediante capas de convoluciÃ³n aprende filtros que, de forma jerÃ¡rquica, reconocen desde bordes y texturas hasta composiciones visuales complejas; las capas de *max-pooling* comprimen la informaciÃ³n, otorgando invarianza a traslaciones y escalas. AsÃ­, la CNN elimina la dependencia de descriptores manuales y se adapta a la gran variabilidad presente en las capturas de videojuegos.

![image](https://github.com/user-attachments/assets/eae4b4b3-83bc-462d-9d12-417ec1106cd6)

#### Â¿Por quÃ© una CNN y no SVM / Random Forest?
- **ExtracciÃ³n de caracterÃ­sticas automÃ¡tica.** La red aprende sola los filtros que distinguen *pixel-art* (Minecraft) de texturas realistas (CS:GO), algo que los enfoques basados en HOG + SVM no logran sin una ingenierÃ­a manual costosa.  
- **Robustez a transformaciones.** ConvoluciÃ³n + pooling mantiene el rendimiento ante cambios de brillo, giros leves o escalados tÃ­picos de un *screenshot*.  
- **Escalabilidad.** La arquitectura puede crecer (mÃ¡s filtros/capas) o migrar, mientras que los modelos clÃ¡sicos requieren redefinir descriptores.  

> **Paper de Referencia**. Breve F. (2023) *From Pixels to Titles: Video Game Identification by Screenshots using Convolutional Neural Networks*, arXiv:2311.15963

### ComposiciÃ³n de la CNN

| Bloque | Capa | ParÃ¡metros clave | PropÃ³sito |
|--------|------|------------------|-----------|
| 1 | `Conv2D(32, 3Ã—3)` + ReLU | Entrada `224Ã—224Ã—3` | Detecta bordes/texturas bÃ¡sicas |
|   | `MaxPooling2D(2Ã—2)` | â€” | Reduce resoluciÃ³n, gana invarianza |
| 2 | `Conv2D(64, 3Ã—3)` + ReLU | â€” | Captura patrones intermedios |
|   | `MaxPooling2D(2Ã—2)` | â€” | â€” |
| 3 | `Conv2D(128, 3Ã—3)` + ReLU | â€” | Reconoce estructuras complejas (HUD, mapas) |
|   | `MaxPooling2D(2Ã—2)` | â€” | â€” |
| â€” | `Flatten()` | â€” | Pasa de 3-D a 1-D |
| â€” | `Dense(128)` + ReLU | â€” | Combina rasgos globales |
| â€” | `Dense(6)` + Softmax | â€” | Probabilidades para las 6 clases |

### SelecciÃ³n de mÃ©tricas

| MÃ©trica | QuÃ© mide | Por quÃ© es Ãºtil |
|---------|----------|-----------------|
| **Accuracy** | ProporciÃ³n de aciertos globales | Indicador general de desempeÃ±o |
| **PrecisiÃ³n** | TP / (TP + FP) por clase | Fiabilidad cuando el modelo â€œafirmaâ€ ser un juego X |
| **Recall** | TP / (TP + FN) por clase | CuÃ¡ntas imÃ¡genes reales de un juego X recupera |
| **F1-score (macro)** | Media balanceada de precisiÃ³n y recall | Resume errores clase a clase |
| **Support** | NÂº de muestras por clase | Conteo de ejemplos reales que pertenecen a cada clase |


### ðŸ”§ ConfiguraciÃ³n de entrenamiento

| Elemento | ConfiguraciÃ³n | Razonamiento |
|----------|--------------|--------------|
| **Optimizador** | Adam | Convergencia estable y sin ajuste manual del *learning rate* |
| **PÃ©rdida** | `categorical_crossentropy` | Adecuada para clasificaciÃ³n *one-hot* |
| **MÃ©trica primaria** | `accuracy` | Feedback rÃ¡pido en cada epoch |

| HiperparÃ¡metro | Valor usado | Por quÃ© se eligiÃ³ |
|----------------|------------|-------------------|
| **Batch size** | **32** | Con 32 imÃ¡genes por lote se logra suficiente aleatoriedad para que el gradiente sea representativo y al mismo tiempo, el consumo de VRAM sea moderado |
| **Ã‰pocas** | **10** | Se realizÃ³ una primera corrida de 10 pasadas completas sobre los datos. Las curvas *loss/accuracy* mostraron estabilizaciÃ³n y ningÃºn signo de overfitting prematuro. |
| **Steps per epoch** | **126** | Se revisan 126 imagenes por Ã©poca ( 4 006 imÃ¡genes de entrenamiento / batch size). Esto permite que cada imagen sea procesada exactamente una vez por Ã©poca. |
| **Validation steps** | **14** | El conjunto de validaciÃ³n quedÃ³ en 445 imÃ¡genes /  batch size. Suficiente para estimar la generalizaciÃ³n sin alargar demasiado cada Ã©poca. |
| **Pesos de clase** | **No aplicados** | El dataset resultÃ³ equilibrado ( 700 Â± 70 imÃ¡genes por clase). Por ello no fue necesario ponderar la pÃ©rdida; todas las clases contribuyen por igual durante el aprendizaje. |

## ðŸ“ˆ EvoluciÃ³n del entrenamiento

| ![Accuracy vs Epoch](ruta/a/accuracy.png) | ![Loss vs Epoch](ruta/a/loss.png) |
|------------------------------------------|----------------------------------|
| **Fig. 1** â€“ Curvas de *accuracy* para entrenamiento y validaciÃ³n. | **Fig. 2** â€“ Curvas de *loss* para entrenamiento y validaciÃ³n. |

![image](https://github.com/user-attachments/assets/2caeae96-fdda-4dc5-9929-ac27283776c8)

![image](https://github.com/user-attachments/assets/9c856dc9-09d9-4a76-b540-ca91af7eebff)

### AnÃ¡lisis de las curvas

- **Crecimiento sÃ³lido**. La *accuracy* de entrenamiento pasa de **0.60 â†’ 0.97** en 7 Ã©pocas, mientras la de validaciÃ³n sube hasta **0.94**.   
- **Loss estable**. La pÃ©rdida de validaciÃ³n oscila entre **0.25 â€“ 0.35**; no hay picos bruscos, seÃ±al de que el modelo generaliza con estabilidad.  

> **ConclusiÃ³n**: el modelo converge rÃ¡pido y mantiene un equilibrio razonable entre ajuste y generalizaciÃ³n; continuar mÃ¡s allÃ¡ de 10 Ã©pocas darÃ­a ganancias marginales y riesgo de sobre-ajuste.




![image](https://github.com/user-attachments/assets/9b306a41-80a2-4210-8941-c95def768ae0)

---

## ðŸ“ˆ DesempeÃ±o en el conjunto **test**

| Clase            | PrecisiÃ³n | Recall | F1-score | Soporte |
|------------------|-----------|--------|----------|---------|
| Clash-Royale     | **0.98**  | **0.99** | **0.99** | 161 |
| Counter-Strike   | **0.99**  | **1.00** | **1.00** | 154 |
| Dead by Daylight | 0.97 | **1.00** | 0.98 | 157 |
| Minecraft        | 0.98 | 0.79 | 0.88 | 157 |
| Overwatch        | 0.96 | 0.77 | 0.86 | 151 |
| Valorant         | 0.74 | 0.98 | 0.84 | 165 |
| **Accuracy global** |  |  | **0.92** | 945 |
| **Macro avg**    | **0.94** | 0.92 | 0.92 | 945 |
| **Weighted avg** | **0.94** | 0.92 | 0.92 | 945 |

![image](https://github.com/user-attachments/assets/9c618a57-4070-4934-8ce4-5b1910412fe0)

### Analisis de la matriz

* **Clash-Royale, Counter-Strike y Dead by Daylight** se clasifican casi perfectos (> 0.97 F1).  
* **Valorant** presenta la mayor confusiÃ³n; absorbe muestras de **Minecraft** (25) y **Overwatch** (30), lo que explica su menor precisiÃ³n (0.74) y el recall alto (0.98).  
* **Minecraft** y **Overwatch** pierden recall por esa misma confusiÃ³n, aunque mantienen precisiÃ³n > 0.95.  





