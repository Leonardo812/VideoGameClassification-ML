# VideoGameClassification-ML

## üéÆ Clasificaci√≥n de Videojuegos mediante Machine Learning

Este proyecto tiene como objetivo desarrollar un modelo capaz de identificar distintos videojuegos a partir de im√°genes, utilizando t√©cnicas de Aprendizaje Autom√°tico (Machine Learning). Esta clasificaci√≥n puede ser √∫til para sistemas de recomendaci√≥n, organizaci√≥n de bibliotecas de juegos o an√°lisis de contenido multimedia relacionado con videojuegos.

Se emplea **Aprendizaje Supervisado**, una rama del Machine Learning en la que el modelo aprende a reconocer patrones a partir de un conjunto de datos etiquetado. A trav√©s del entrenamiento con estas im√°genes, el modelo es capaz de predecir correctamente la categor√≠a o el videojuego correspondiente de nuevas im√°genes no vistas.

---

## üïπÔ∏è Clases del Modelo

El modelo ha sido entrenado para reconocer y clasificar im√°genes de distintos videojuegos populares, cada uno con caracter√≠sticas visuales y est√©ticas particulares. Estas son las categor√≠as de videojuegos que el modelo identifica, junto con una breve descripci√≥n de cada una:

- **Dead by Daylight**  
  Juego multijugador asim√©trico (1 vs 4) de horror y supervivencia. Un jugador asume el rol de asesino, mientras los dem√°s intentan sobrevivir.  
  **Estilo visual:** Entornos oscuros, iluminaci√≥n tenue y predominancia de colores opacos y sombr√≠os.  
  **Perspectiva:** 3D en tercera persona.

- **Counter-Strike: Global Offensive (CS:GO)**  
  Shooter t√°ctico multijugador por equipos (5v5), centrado en enfrentamientos entre terroristas y antiterroristas.  
  **Estilo visual:** Ambientes urbanos o industriales, paleta de colores realista y sobria.  
  **Perspectiva:** 3D en primera persona.

- **Valorant**  
  Shooter t√°ctico multijugador que combina mec√°nicas de disparo con habilidades √∫nicas por personaje.  
  **Estilo visual:** Gr√°ficos estilizados con colores vivos, mapas bien iluminados y efectos visuales llamativos.  
  **Perspectiva:** 3D en primera persona.

- **Clash Royale**  
  Juego de estrategia en tiempo real para m√≥viles, basado en cartas coleccionables y batallas r√°pidas entre dos jugadores.  
  **Estilo visual:** Est√©tica caricaturesca en 2.5D, colores brillantes y animaciones simplificadas.  
  **Perspectiva:** Vista cenital (de arriba hacia abajo).

- **Minecraft**  
  Juego de construcci√≥n y supervivencia en un mundo abierto generado por bloques.  
  **Estilo visual:** Est√©tica pixelada en 3D, colores variados pero con texturas simples y cuadradas.  
  **Perspectiva:** Puede alternar entre primera y tercera persona.

- **Overwatch**  
  Shooter por equipos con enfoque en h√©roes, cada uno con habilidades y roles espec√≠ficos.  
  **Estilo visual:** Gr√°ficos coloridos y estilizados, ambientaciones futuristas y personajes visualmente distintivos.  
  **Perspectiva:** 3D en primera persona.

---

## üìÅ Generaci√≥n y selecci√≥n del conjunto de datos

Para este proyecto se utiliz√≥ el dataset [**Videogame Image Classification**](https://www.kaggle.com/datasets/juanmartinzabala/videogame-image-classification?resource=download-directory) disponible en Kaggle, el cual contiene capturas de pantalla de diversos videojuegos populares.

### üîç Proceso de limpieza y selecci√≥n

A partir del conjunto original, se realiz√≥ una limpieza significativa, seleccionando √∫nicamente 6 de las 21 clases disponibles. Esta decisi√≥n se tom√≥ porque muchas clases presentaban im√°genes con problemas como:

- Capturas limitadas a una sola zona del videojuego.
- Presencia de elementos no relacionados (como c√°maras de streamers o superposiciones gr√°ficas de transmisiones).
- Poca diversidad en escenarios y contenido visual del juego.

Estas limitaciones pod√≠an afectar negativamente la capacidad del modelo para generalizar, por lo que se opt√≥ por trabajar solo con clases visualmente m√°s consistentes y representativas.

### üì¶ Reducci√≥n y balanceo del dataset

Cada clase del dataset original conten√≠a aproximadamente 4,000 im√°genes para entrenamiento y 1,000 para prueba. No obstante, se redujo intencionalmente la cantidad de im√°genes a un aproximado de:

- **700 im√°genes por clase para entrenamiento**
- **150 im√°genes por clase para prueba**
  
Adicionalmente se uso el 10% de datos de cada clase como datos de validaci√≥n.

Esta reducci√≥n tuvo como objetivo priorizar la calidad y la diversidad del contenido, manteniendo un balance entre clases y una proporci√≥n de **70% para entrenamiento, 10% para validaci√≥n y 20% para prueba**.

---

## üìä Distribuci√≥n de los datos

Despu√©s del proceso de limpieza y selecci√≥n, el conjunto de datos qued√≥ conformado por un total de **4,451 im√°genes para entrenamiento**, distribuidas de manera balanceada entre las seis clases seleccionadas:

| Videojuego           | Im√°genes (train) |
|----------------------|------------------|
| Dead by Daylight     | 704              |
| Counter-Strike       | 733              |
| Valorant             | 789              |
| Clash Royale         | 718              |
| Minecraft            | 787              |
| Overwatch            | 720              |
| **Total**            | **4,451**        |

| Videojuego           | Im√°genes (test) |
|----------------------|------------------|
| Dead by Daylight     | 157              |
| Counter-Strike       | 154              |
| Valorant             | 165              |
| Clash Royale         | 161              |
| Minecraft            | 157              |
| Overwatch            | 151              |
| **Total**            | **945**        |

Esta distribuci√≥n permite mantener una representaci√≥n relativamente equilibrada entre las clases, lo que ayuda a que el modelo aprenda patrones visuales distintivos de cada videojuego. En caso de ser necesario, se podr√° incrementar el n√∫mero de im√°genes por clase para mejorar el rendimiento del modelo o reforzar aquellas categor√≠as que presenten menor precisi√≥n durante las pruebas.

## üõ†Ô∏è Preprocesado y t√©cnicas de aumento de datos

Para mejorar la capacidad del modelo para generalizar y hacerlo m√°s robusto frente a las distintas condiciones gr√°ficas en las que pueden presentarse los videojuegos (por ejemplo, baja calidad, capturas con diferente iluminaci√≥n o resoluci√≥n), se aplicaron las siguientes t√©cnicas de preprocesamiento:

### üîπ Reescalado (normalizaci√≥n)
Cada valor de p√≠xel se divide entre **255** (`rescale=1./255`) para transformar el rango de los p√≠xeles de **[0, 255] a [0, 1]**. Esto estabiliza el proceso de optimizaci√≥n y mejora la convergencia del modelo durante el entrenamiento.

### üîπ Redimensionamiento (resize)
Todas las im√°genes se redimensionaron al tama√±o de **224x224 p√≠xeles**, que es un est√°ndar com√∫n para modelos de redes neuronales convolucionales (CNN). Esto asegura consistencia en la entrada de datos.

### üîπ Aumento de datos (data augmentation)
Se aplicaron transformaciones aleatorias a las im√°genes del conjunto de entrenamiento para simular una mayor diversidad visual sin necesidad de agregar nuevas im√°genes. Las transformaciones incluyen:

- **Giro horizontal aleatorio** (`RandomFlip`)
- **Rotaci√≥n aleatoria** (`RandomRotation`)
- **Zoom aleatorio** (`RandomZoom`)

Estas t√©cnicas ayudan a reducir el sobreajuste y permiten que el modelo aprenda caracter√≠sticas m√°s generales del contenido visual.

![image](https://github.com/user-attachments/assets/65bc234d-d7e0-4083-ab72-3a0ad6e2556b)

## ü§ñ Construcci√≥n del modelo

### Arquitectura CNN
Una **Red Neuronal Convolucional (CNN)** es una arquitectura de red para Deep Learning que aprende directamente a partir de datos. Mediante capas de convoluci√≥n aprende filtros que, de forma jer√°rquica, reconocen desde bordes y texturas hasta composiciones visuales complejas; las capas de *max-pooling* comprimen la informaci√≥n, otorgando invarianza a traslaciones y escalas. As√≠, la CNN elimina la dependencia de descriptores manuales y se adapta a la gran variabilidad presente en las capturas de videojuegos.

![image](https://github.com/user-attachments/assets/eae4b4b3-83bc-462d-9d12-417ec1106cd6)

#### ¬øPor qu√© una CNN y no SVM / Random Forest?

La elecci√≥n de una red neuronal convolucional (CNN) se justifica en tres frentes, todos documentados en el trabajo de Breve [1]:

- **Extracci√≥n de caracter√≠sticas autom√°tica.** El estudio muestra que las CNN obtienen ‚Äúresultados sobresalientes sin necesidad de describir manualmente las caracter√≠sticas de cada juego‚Äù [1, Sec. I]. En contraste, m√©todos cl√°sicos como HOG + SVM requieren dise√±ar descriptores a mano, lo que limita la capacidad de adaptaci√≥n cuando se a√±aden t√≠tulos con estilos gr√°ficos nuevos. 
- **Robustez a transformaciones.** Las etapas de convoluci√≥n y *max-pooling* confieren a la red ‚Äúinvariancia natural a traslaciones, rotaciones y cambios de escala‚Äù. Esa propiedad es crucial porque las capturas de pantalla llegan con distintas resoluciones, encuadres y niveles de brillo; un SVM o un Random Forest no poseen esa resistencia de forma inherente.  
- **Escalabilidad.** La arquitectura puede crecer (m√°s filtros/capas) o migrar, mientras que los modelos cl√°sicos requieren redefinir descriptores.  

> **Paper de Referencia**. Breve F. (2023) *From Pixels to Titles: Video Game Identification by Screenshots using Convolutional Neural Networks*, arXiv:2311.15963

### Composici√≥n de la CNN

| Bloque | Capa | Par√°metros clave | Prop√≥sito |
|--------|------|------------------|-----------|
| 1 | `Conv2D(32, 3√ó3)` + ReLU | Entrada `224√ó224√ó3` | Detecta bordes/texturas b√°sicas |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | Reduce resoluci√≥n, gana invarianza |
| 2 | `Conv2D(64, 3√ó3)` + ReLU | ‚Äî | Captura patrones intermedios |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | ‚Äî |
| 3 | `Conv2D(128, 3√ó3)` + ReLU | ‚Äî | Reconoce estructuras complejas (HUD, mapas) |
|   | `MaxPooling2D(2√ó2)` | ‚Äî | ‚Äî |
| ‚Äî | `Flatten()` | ‚Äî | Pasa de 3-D a 1-D |
| ‚Äî | `Dense(128)` + ReLU | ‚Äî | Combina rasgos globales |
| ‚Äî | `Dense(6)` + Softmax | ‚Äî | Probabilidades para las 6 clases |

### Selecci√≥n de m√©tricas

| M√©trica | Qu√© mide | Por qu√© es √∫til |
|---------|----------|-----------------|
| **Accuracy** | Proporci√≥n de aciertos globales | Indicador general de desempe√±o |
| **Precisi√≥n** | TP / (TP + FP) por clase | Fiabilidad cuando el modelo ‚Äúafirma‚Äù ser un juego X |
| **Recall** | TP / (TP + FN) por clase | Cu√°ntas im√°genes reales de un juego X recupera |
| **F1-score (macro)** | Media balanceada de precisi√≥n y recall | Resume errores clase a clase |
| **Support** | N¬∫ de muestras por clase | Conteo de ejemplos reales que pertenecen a cada clase |


### üîß Configuraci√≥n de entrenamiento

| Elemento | Configuraci√≥n | Razonamiento |
|----------|--------------|--------------|
| **Optimizador** | Adam | Convergencia estable y sin ajuste manual del *learning rate* |
| **P√©rdida** | `categorical_crossentropy` | Adecuada para clasificaci√≥n *one-hot* |
| **M√©trica primaria** | `accuracy` | Feedback r√°pido en cada epoch |

| Hiperpar√°metro | Valor usado | Por qu√© se eligi√≥ |
|----------------|------------|-------------------|
| **Batch size** | **32** | Con 32 im√°genes por lote se logra suficiente aleatoriedad para que el gradiente sea representativo y al mismo tiempo, el consumo de VRAM sea moderado |
| **√âpocas** | **10** | Se realiz√≥ una primera corrida de 10 pasadas completas sobre los datos. Las curvas *loss/accuracy* mostraron estabilizaci√≥n y ning√∫n signo de overfitting prematuro. |
| **Steps per epoch** | **126** | Se revisan 126 imagenes por √©poca ( 4 006 im√°genes de entrenamiento / batch size). Esto permite que cada imagen sea procesada exactamente una vez por √©poca. |
| **Validation steps** | **14** | El conjunto de validaci√≥n qued√≥ en 445 im√°genes /  batch size. Suficiente para estimar la generalizaci√≥n sin alargar demasiado cada √©poca. |
| **Pesos de clase** | **No aplicados** | El dataset result√≥ equilibrado ( 700 ¬± 70 im√°genes por clase). Por ello no fue necesario ponderar la p√©rdida; todas las clases contribuyen por igual durante el aprendizaje. |

## üìà Evoluci√≥n del entrenamiento primera version del modelo

![image](https://github.com/user-attachments/assets/2caeae96-fdda-4dc5-9929-ac27283776c8)

![image](https://github.com/user-attachments/assets/9c856dc9-09d9-4a76-b540-ca91af7eebff)

### An√°lisis de las curvas

- **Crecimiento s√≥lido**. La *accuracy* de entrenamiento pasa de **0.60 ‚Üí 0.97** en 7 √©pocas, mientras la de validaci√≥n sube hasta **0.94**.   
- **Loss estable**. La p√©rdida de validaci√≥n oscila entre **0.25 ‚Äì 0.35**; no hay picos bruscos, se√±al de que el modelo generaliza con estabilidad.  

> **Conclusi√≥n**: el modelo converge r√°pido y mantiene un equilibrio razonable entre ajuste y generalizaci√≥n; continuar m√°s all√° de 10 √©pocas dar√≠a ganancias marginales y riesgo de sobre-ajuste.




![image](https://github.com/user-attachments/assets/9b306a41-80a2-4210-8941-c95def768ae0)

---

## üìà Desempe√±o en el conjunto **test**

| Clase            | Precisi√≥n | Recall | F1-score | Soporte |
|------------------|-----------|--------|----------|---------|
| Clash-Royale     | **0.98**  | **0.99** | **0.99** | 161 |
| Counter-Strike   | **0.99**  | **1.00** | **1.00** | 154 |
| Dead by Daylight | 0.97 | **1.00** | 0.98 | 157 |
| Minecraft        | 0.98 | 0.79 | 0.88 | 157 |
| Overwatch        | 0.96 | 0.77 | 0.86 | 151 |
| Valorant         | 0.74 | 0.98 | 0.84 | 165 |
| **Accuracy global** |  |  | **0.92** | 945 |
| **Macro avg**    | **0.94** | 0.92 | 0.92 | 945 |
| **Weighted avg** | **0.94** | 0.92 | 0.92 | 945 |

![image](https://github.com/user-attachments/assets/9c618a57-4070-4934-8ce4-5b1910412fe0)

### Analisis de la matriz

* **Clash-Royale, Counter-Strike y Dead by Daylight** se clasifican casi perfectos (> 0.97 F1).  
* **Valorant** presenta la mayor confusi√≥n; absorbe muestras de **Minecraft** (25) y **Overwatch** (30), lo que explica su menor precisi√≥n (0.74) y el recall alto (0.98).  
* **Minecraft** y **Overwatch** pierden recall por esa misma confusi√≥n, aunque mantienen precisi√≥n > 0.95.  

### Resumen global

- **Accuracy test = 0.92** confirma que la CNN generaliza bien a im√°genes no vistas por lo que el modelo funciona. Sin embargo es muy probable que exitan confusiones que se concentren en los juegos (Valorant, Overwatch yMinecraft-pixel-like). Pues haciendo pruebas de prediccion son los juegos que el modelo confunde mas comunmente. Esto puede ser debido a su similitud visual.

### üõ†Ô∏è Refinamiento del modelo

#### Problema detectado  
Aunque la CNN obten√≠a **92 % de acierto** en el *test set*, fallaba en dos situaciones t√≠picas al clasificar capturas externas:

1. **Iluminaci√≥n o filtros extremos**  
   Mapas nocturnos, sobreexpuestos o con *shaders* alteraban la paleta y el modelo confund√≠a Valorant ‚Üî Overwatch o Minecraft ‚Üî Valorant.
2. **Ausencia de HUD**  
   Algunas capturas sin barra de salud/munici√≥n perd√≠an referencias clave; la red asignaba la imagen a la clase visualmente m√°s parecida.

Para corregir estos sesgos se siguieron tres pasos:

Se ampli√≥ el set de datos incorporando alrededor de cien capturas adicionales para cada una de las clases problem√°ticas‚ÄîValorant, Overwatch y Minecraft poniendo especial atenci√≥n en incluir mapas poco frecuentes, escenas sin HUD y material promocional que conserva la paleta y el estilo propios de cada t√≠tulo.

Se depuraron im√°genes redundantes o con superposiciones de streaming, de modo que la diversidad efectiva aumentara sin inflar artificialmente la base de datos.

Se a√±adi√≥ regularizaci√≥n adicional activando un Dropout del 20 % en la capa densa final. Esto limita la co-adaptaci√≥n de neuronas y contrarresta el leve sobre-ajuste observado a partir de la sexta √©poca de entrenamiento original.

Tras la expansi√≥n, el conjunto de entrenamiento termino de la siguiente manera:

| Videojuego           | Im√°genes (train) |
|----------------------|------------------|
| Dead by Daylight     | 825              |
| Counter-Strike       | 849              |
| Valorant             | 912              |
| Clash Royale         | 718              |
| Minecraft            | 864              |
| Overwatch            | 867              |
| **Total**            | **4,451**        |

*(El set de validaci√≥n se mantuvo en 10 % de cada clase para conservar la proporci√≥n 70-20-10).*

### üìä Resultados | Comparaci√≥n antes vs. despu√©s del refinamiento

**Desempe√±o global.**  
El accuracy de prueba pas√≥ de **0.92 a 0.95** y el F1 macro subi√≥ de 0.92 a **0.95**. Las curvas de entrenamiento muestran que la diferencia entre train y val sigue por debajo de 5 p.p., por lo que no apareci√≥ sobre-ajuste adicional.

## üìà Desempe√±o en el conjunto **test**

| Clase            | Precisi√≥n | Recall | F1-score | Soporte |
|------------------|-----------|--------|----------|---------|
| Clash-Royale     | **0.89**  | **1.00** | **0.94** | 161 |
| Counter-Strike   | **0.94**  | **1.00** | **0.97** | 154 |
| Dead by Daylight | 0.95 | **1.00** | 0.98 | 157 |
| Minecraft        | 1.00 | 0.88 | 0.94 | 157 |
| Overwatch        | 0.97 | 0.91 | 0.94 | 151 |
| Valorant         | 0.97 | 0.93 | 0.95 | 165 |
| **Accuracy global** |  |  | **0.95** | 945 |
| **Macro avg**    | **0.96** | 0.95 | 0.95 | 945 |
| **Weighted avg** | **0.96** | 0.95 | 0.95 | 945 |

**Cambios por videojuego.**

- **Clash Royale** ‚Äì El F1 baja de 0.98 a **0.94**. Los trece falsos positivos provenientes de Minecraft sugieren que, al no haberse a√±adido material nuevo para Clash Royale, algunas de las im√°genes incorporadas a las otras clases (en especial Minecraft con shaders y tonalidades c√°lidas) resultan visualmente parecidas a escenas del juego, generando la confusi√≥n.
- **Counter-Strike** ‚Äì Mantiene un desempe√±o casi perfecto: F1 pasa de 0.99 a **0.97** (variaci√≥n m√≠nima).  
- **Dead by Daylight** ‚Äì Mejora de 0.97 a **0.98**.  
- **Minecraft** ‚Äì Mejora clara: F1 sube de 0.88 a **0.94** gracias a ejemplos sin HUD y con *shaders*.  
- **Overwatch** ‚Äì F1 salta de 0.86 a **0.94**; se reduce dr√°sticamente la confusi√≥n con Valorant.  
- **Valorant** ‚Äì Precisi√≥n se dispara (0.74 ‚Üí 0.97) y el F1 llega a **0.95**; el modelo comete muchos menos falsos positivos.

Los gr√°ficos y la nueva matriz de confusi√≥n se muestran a continuaci√≥n:

![image](https://github.com/user-attachments/assets/6328275a-401c-4f0b-a6bf-85624111ff72)


- Las confusiones Valorant ‚Üí Overwatch caen de 30 a **4**.  
- Minecraft ‚Üí Valorant desaparece (25 ‚Üí **0**), aunque parte migra a Clash Royale y Dead by Daylight.  
- Counter-Strike y Dead by Daylight conservan todos sus aciertos en la diagonal.
- Esos errores se reducen a 0 (Minecraft ‚Üí Valorant) y 4 (Overwatch ‚Üí Valorant).  
- Aparecen nuevas confusiones menores de Minecraft y Overwatch hacia Clash-Royale (13 y 6 casos) y Dead by Daylight (4 y 3 casos).  

> **Interpretaci√≥n:** las escenas oscuras o de tonos c√°lidos que antes se confund√≠an con Valorant ahora se reparten entre Clash-Royale y Dead by Daylight, lo que explica la ligera ca√≠da de F1 en Clash-Royale.


![image](https://github.com/user-attachments/assets/17350ceb-59fc-4fd5-a34d-c160673a6cf9)

![image](https://github.com/user-attachments/assets/91fed021-e024-4de0-b200-fe9e329ce531)




### Imagenes de comparaci√≥n de predicciones

### Modelo previo sin refinar

![image](https://github.com/user-attachments/assets/e76a878b-e12d-47f0-abc1-3088872d5f69)

![image](https://github.com/user-attachments/assets/69cbbd88-ec00-4356-bdb6-fb90725a55e1)

![image](https://github.com/user-attachments/assets/369fd935-a05c-4083-a911-8af2c4752f89)

![image](https://github.com/user-attachments/assets/fa50ccb1-7c63-4f1e-98a7-2fdc8556cc74)

![image](https://github.com/user-attachments/assets/60fcb41f-7dbe-4974-8baf-37331cc41b20)

![image](https://github.com/user-attachments/assets/d22c945f-d025-4797-9660-739c84d8e12a)

![image](https://github.com/user-attachments/assets/b3660e4a-72f3-4e37-9222-bdcd8021e580)





### Modelo refinado

![image](https://github.com/user-attachments/assets/f46070cc-fe65-4281-a35c-1bb1f71acf24)

![image](https://github.com/user-attachments/assets/a8794a13-642f-495d-8f02-60c5ef752342)

![image](https://github.com/user-attachments/assets/72f2e5bb-84f9-4ddc-8a72-fc53e2c282d2)

![image](https://github.com/user-attachments/assets/875a13a8-4d9d-4adc-af10-a4613bf87d25)

![image](https://github.com/user-attachments/assets/b271feb6-7f32-4122-bc7e-7600adae475f)

![image](https://github.com/user-attachments/assets/f51991a0-e478-48cd-930d-8197593ca025)

![image](https://github.com/user-attachments/assets/832bd11f-b95c-4f66-b710-6b65e2af2b75)




> **Conclusi√≥n.** Reforzar la variedad del conjunto de datos enfocado en mapas raros, luminaci√≥n variada y capturas sin HUD y aplicar Dropout bast√≥ para recuperar once puntos porcentuales de precisi√≥n en escenarios reales, sin necesidad de cambiar la arquitectura principal. La √∫nica oportunidad clara de mejora queda en **Clash Royale**, donde convendr√≠a a√±adir escenas diurnas con filtros cartoon para diferenciarlo de los *shaders* de Minecraft.









